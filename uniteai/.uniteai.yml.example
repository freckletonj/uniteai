##################################################
#
#              _ _             _
#             (_) |           (_)
#  _   _ _ __  _| |_ ___  __ _ _
# | | | | '_ \| | __/ _ \/ _` | |
# | |_| | | | | | ||  __/ (_| | |
#  \__,_|_| |_|_|\__\___|\__,_|_|
#
#
#
# EXAMPLE CONFIG
#
#   **RESTART YOUR EDITOR AFTER EDITING THIS**
#
# Please edit this file per your liking. Add your OpenAI API Key, choose what
# features you want to include, what models you want, etc.
#
#
# THINGS TO KNOW:
#
# uniteai.openai:
#   requires a paid API key
#
# uniteai.transcription:
#   on first use, this will download and cache the model you choose, then run locally
#
# uniteai.document:
#   on first use, this will download and cache the model you choose, then run locally
#
# uniteai.local_llm:
#   this requires you to run `uniteai_llm` from a terminal
#
# uniteai.contrib.example:
#   this shows off some LSP capabilities. You only want to check this out if
#   you're developing features.
#
# uniteai.contrib.text_to_speech:
#   not ready for primetime yet
#
#
##################################################

##########
# LSP

modules:
  - uniteai.openai
  - uniteai.transcription
  - uniteai.document
  # - uniteai.local_llm
  # - uniteai.contrib.text_to_speech
  # - uniteai.contrib.example

# Editor typically connects via stdio, but if you change it to use TCP, here's the port
lsp_port: 5033


##########
# OpenAI

openai:
  api_key: "sk-..."
  completion_engine: 'text-davinci-002'
  chat_engine: 'gpt-3.5-turbo'
  max_length: 1000


##########
# Transcription: `uniteai.transcription`

transcription:
  volume_threshold: 100  # see `speech_recognition` docs for energy threshold
  model_type: 'whisper'
  model_size: 'base'  # tiny, base, small, medium, large-v2
  # model_path: '/home/me/path/to/whisper-base'  # if you don't provide, it will be downloaded and cached


##########
# Document Chat

document:
  download_cache: './download_cache/'
  embedding_cache: './embedding_cache/'
  db_path: 'db.sqlite3'
  model_name: 'thenlper/gte-large'
  denoise_window_size: 1000
  denoise_poly_order: 1
  percentile: 95


##########
# Local LLM: `uniteai.local_llm`

local_llm:
  port: 8000  # LSP connects to LLM server via this port
  host: 'localhost'
  # model_name_or_path: '/home/me/path/to/falcon-7b-instruct/'
  # model_name_or_path: 't5-base'
  model_name_or_path: 'codellama/CodeLlama-7b-Python-hf'
  model_commit: '51955db0c7f350e799b6cd837e4974017761d79a'
  device_map: 'auto'
  torch_dtype: "bf16"
  # attn_implementation: "flash_attention_2"


  # Falcon params
  max_length: 1000
  top_k: 10


##########
# Example: `uniteai.contrib.example`
#
# a feature that counts up

example:
  start_digit: 13
  end_digit: 1000
  delay: 0.4
